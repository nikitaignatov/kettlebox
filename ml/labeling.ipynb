{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,InputLayer,MaxPool2D\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# confusion matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.signal import argrelextrema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.normalize import acc_scalar2, frequency, magnitude\n",
    "from lib.plot import plot_activity\n",
    "from lib.transform import transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN = \"Az\"\n",
    "df = transform()[[COLUMN]]\n",
    "transform()[['Ax','Ay','Az']].iloc[0:1000].plot(figsize=(24, 12))\n",
    "# df.Time = df.Time.dt.float\n",
    "\n",
    "hz = 100\n",
    "min = int(0.5*hz)\n",
    "max = 5*hz\n",
    "increment = 100\n",
    "\n",
    "\n",
    "def crosscorr(datax, datay, lag=0):\n",
    "    return datax.corr(datay.shift(lag), method=\"pearson\")\n",
    "\n",
    "max = 1000\n",
    "rs =pd.DataFrame(columns=['cor','lag'])\n",
    "\n",
    "for x in range(0,int(max),5):\n",
    "  offset= x\n",
    "  pa = df.iloc[34:97]\n",
    "  x = pa.reset_index()[COLUMN]\n",
    "  y = df.iloc[offset:97-34 +offset].reset_index()[COLUMN]\n",
    "  pa[COLUMN].plot(c='b',style='-.')\n",
    "  c = crosscorr(x,y)\n",
    "  rs= rs.append({'cor':c,'lag':offset},ignore_index=True)\n",
    "n = 2\n",
    "rs['max'] = rs.iloc[argrelextrema(rs['cor'].values, np.greater_equal, order=n)[0]]['cor']\n",
    "\n",
    "rs =rs[['max','lag','cor']].dropna()\n",
    "rs=rs.set_index(rs['lag'])\n",
    "plt.scatter(rs.index, rs['max'], c='r')\n",
    "[plt.axvline(m, c='r', linewidth=0.3) for m in rs['lag'].to_list()]\n",
    "plt.plot(rs.index, rs['cor'])\n",
    "plt.show()\n",
    "rs.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = transform()\n",
    "\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filter requirements.\n",
    "order = 6\n",
    "fs = 50.0       # sample rate, Hz\n",
    "cutoff = 1.667  # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "# Get the filter coefficients so we can check its frequency response.\n",
    "b, a = butter_lowpass(cutoff, fs, order)\n",
    "ax = \"y\"\n",
    "i=1000\n",
    "data = df[\"A{}\".format(ax)][:i].to_list()\n",
    "\n",
    "y = butter_lowpass_filter(data, cutoff, fs, order)\n",
    "df[\"A{}l\".format(ax)] = pd.DataFrame(y)\n",
    "\n",
    "plt.plot(df.Time[:i], data, 'b-', label='data')\n",
    "plt.plot(df.Time[:i], y, 'g-', linewidth=2, label='filtered data')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "window = 10\n",
    "\n",
    "# df['Axs'] = (df['Ax'].apply(lambda x: (x+4.0)/8.0)).rolling(window).mean()\n",
    "# df['Ays'] = (df['Ay'].apply(lambda x: (x+4.0)/8.0)).rolling(window).mean()\n",
    "# df['Azs'] = (df['Az'].apply(lambda x: (x+4.0)/8.0)).rolling(window).mean()\n",
    "# df['Gxs'] = (df['Gx'].apply(lambda x: (x+500.0)/1000.0))\n",
    "# df['Gys'] = (df['Gy'].apply(lambda x: (x+500.0)/1000.0))\n",
    "# df['Gzs'] = (df['Gz'].apply(lambda x: (x+500.0)/1000.0))\n",
    "# df['Axd'] = df['Axs'].diff().rolling(window).mean()\n",
    "# df['Ayd'] = df['Ays'].diff().rolling(window).mean()\n",
    "df[\"A{}d\".format(ax)] = df[\"A{}l\".format(ax)].diff().rolling(window).mean()\n",
    "\n",
    "def plot_activity_normalized(activity, df, axis, i=1000):\n",
    "    data = df[df['Activity'] == activity][[\"A{}\".format(axis),'A{}d'.format(axis), 'A{}l'.format(axis)]][:i]\n",
    "    axis = data.plot(subplots=True, figsize=(16, 12),\n",
    "                     title=activity)\n",
    "    for ax in axis:\n",
    "        ax.legend(loc='lower left', bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "plot_activity_normalized('Swing Left',df,ax,i=1000)\n",
    "#plt.magnitude_spectrum(df[df['Activity']=='Swing Left']['Ay'][45:1845].values, Fs=50)\n",
    "plt.show()\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.specgram(df[df['Activity']=='Swing Left']['Ays'][45:1845].values, Fs=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the number of datapoints for each indivudal exercise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Activity'].value_counts().plot(kind='bar', title='Plotting records by activity type', figsize=(10, 4),align='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features\n",
    "Normalize the accelerometer and gyroscope values and extract other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scalar2(df)\n",
    "magnitude(df)\n",
    "frequency(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the accelerometer and gyro data\n",
    "Now it is time to review the actual contents of the sensor data for different excersizes and see if there are any issues with the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plot import plot_datasets\n",
    "plot_datasets(df,i=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plot import plot_datasets_magnitude\n",
    "\n",
    "plot_datasets_magnitude(df, i=7000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plot import plot_datasets_normalized\n",
    "plot_datasets_normalized(df,i=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plot import plot_activity_normalized\n",
    "plot_activity_normalized('Swing Right',df,i=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activity_normalized('Press',df,i=6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samping frequency \n",
    "The frequency is different for some of the sampling data due to the different methods that have been used for data recording.\n",
    "\n",
    "Original prototype used to publish data over HTTP and esp32 was able to achieve a sampling rate of 50hz. \n",
    "\n",
    "After the first model has been trained the prediction data has been added to the samples, this decreased the sampling rate down to 25hz. This has been improved in the 3 version of the hardware where sampling rate including the prediction output is 100hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hz'].value_counts().sort_index().plot(kind='bar', title='Plotting records by frequency in Hz', figsize=(16, 6),align='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency on log scale\n",
    "TODO: Need to look into why there are some negative values, seems strange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt1 = df['Hz'].value_counts().sort_index().plot(kind='bar', title='Samples count by frequency in Hz - Log scale', figsize=(16, 6),align='center')\n",
    "plt1.yaxis.grid()\n",
    "plt1.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activity_normalized('Press',df,i=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[50:55]\n",
    "plot_activity('Swing Both Hands',df,i=1845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.magnitude_spectrum(df[df['Activity']=='Swing Left']['Az'][45:1845].values, Fs=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.specgram(df[df['Activity']=='Swing Both Hands']['Am'][45:845].values,NFFT=10, Fs=50,noverlap=4,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot3d_e(name, sensor, norm,n):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    xs = df[df['Activity']==name][sensor+'y'+norm].head(n).values\n",
    "    #ys = df[df['Activity']==name][sensor+'y'+norm].head(n).values\n",
    "    ys = df[df['Activity']==name]['Time'].head(n).values\n",
    "    zs = df[df['Activity']==name][sensor+'z'+norm].head(n).values\n",
    "    ax.plot(xs=xs,ys=ys,zs=zs,zdir='z')\n",
    "    \n",
    "    #ax.contour(X=xs,Y=ys,Z=zs)\n",
    "plot3d_e('Press Left','A','',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activity_normalized('Swing Both Hands',df,i=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "df['Label'] = label.fit_transform(df['Activity'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples2(data):\n",
    "    GESTURES = label.classes_\n",
    "    SAMPLES_PER_GESTURE = 40\n",
    "    NUM_GESTURES = len(GESTURES)\n",
    "    ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    # read each csv file and push an input and output\n",
    "    for gesture_index in range(NUM_GESTURES):\n",
    "      gesture = GESTURES[gesture_index]\n",
    "      print(f\"Processing index {gesture_index} for gesture '{gesture}'.\")\n",
    "\n",
    "      output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
    "\n",
    "      df = data[data['Activity'] == gesture].head(6000).copy()\n",
    "\n",
    "      # calculate the number of gesture recordings in the file\n",
    "      num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
    "\n",
    "      print(f\"\\tThere are {num_recordings} recordings of the {gesture} gesture.\")\n",
    "\n",
    "      for i in range(num_recordings):\n",
    "        tensor = []\n",
    "        for j in range(SAMPLES_PER_GESTURE):            \n",
    "            \n",
    "          index = i * SAMPLES_PER_GESTURE + j\n",
    "          # normalize the input data, between 0 to 1:\n",
    "          # - acceleration is between: -4 to +4\n",
    "          # - gyroscope is between: -2000 to +2000\n",
    "          tensor += [\n",
    "          #(df['Ax'][index] + 4.0) / 8.0,\n",
    "          #(df['Ay'][index] + 4.0) / 8.0,\n",
    "          #(df['Az'][index] + 4.0) / 8.0,\n",
    "          #(df['Gx'][index] + 500.0) / 1000.0,\n",
    "          #(df['Gy'][index]  + 500.0) / 1000.0,\n",
    "          #(df['Gz'][index]  + 500.0) / 1000.0,\n",
    "          \n",
    "              \n",
    "           math.sqrt(df['Ax'][index] ** 2) / 4,\n",
    "           math.sqrt(df['Ay'][index] ** 2) / 4,\n",
    "           math.sqrt(df['Az'][index] ** 2) / 4,\n",
    "           math.sqrt(df['Gx'][index] ** 2) / 500,\n",
    "           math.sqrt(df['Gy'][index] ** 2) / 500,\n",
    "           math.sqrt(df['Gz'][index] ** 2) / 500,\n",
    "          #    df['Am'][index],\n",
    "          #    df['Gm'][index],\n",
    "          #    math.atan2(df['Ay'][index],df['Az'][index]),\n",
    "        # math.atan2(-df['Ax'][index], math.sqrt(df['Ay'][index]**2 +(df['Az'][index] **2)))\n",
    "          ]\n",
    "\n",
    "        inputs.append(tensor)\n",
    "        outputs.append(output)\n",
    "\n",
    "    # convert the list to numpy array\n",
    "    inputs = np.array(inputs)\n",
    "    outputs = np.array(outputs)\n",
    "    return inputs, outputs\n",
    "inputs,outputs = get_samples2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
    "# https://stackoverflow.com/a/37710486/2020087\n",
    "num_inputs = len(inputs)\n",
    "randomize = np.arange(num_inputs)\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
    "inputs = inputs[randomize]\n",
    "outputs = outputs[randomize]\n",
    "\n",
    "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
    "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
    "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
    "\n",
    "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(InputLayer(input_shape=inputs_train[0].shape))\n",
    "\n",
    "#model.add(Conv2D(50,[2,2], activation='relu',input_shape=inputs_train[0].shape))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(Conv2D(12,[2,2], activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "#model.add(Flatten())\n",
    "\n",
    "#model.add(Dense(64, activation='relu'),input_shape=inputs_train[0].shape)\n",
    "#model.add(Dropout(0.5))\n",
    "NUM_GESTURES= len(label.classes_)\n",
    "model = Sequential()\n",
    "#model.add(Conv2D(50,[2,2], activation='relu',input_shape=inputs_train[0].shape))\n",
    "model.add(Dense(16, activation='relu', input_shape =inputs_train[0].shape)) # relu is used for performance\n",
    "model.add(Dense(16, activation='relu')) # relu is used for performance\n",
    "model.add(Dropout(0.1)) # relu is used for performance\n",
    "model.add(Dense(20, activation='relu')) # relu is used for performance\n",
    "model.add(Dropout(0.2)) # relu is used for performance\n",
    "model.add(Dense(32, activation='relu')) # relu is used for performance\n",
    "model.add(Dense(16, activation='relu')) # relu is used for performance\n",
    "model.add(Dense(NUM_GESTURES, activation='softmax')) # softmax is used, because we only expect one gesture to occur per input\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(inputs_train, outputs_train, epochs=50, batch_size=10, validation_data=(inputs_validate, outputs_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(inputs_test)\n",
    "\n",
    "\n",
    "rounded_labels=np.argmax(outputs_test, axis=1)\n",
    "rounded_labels[1]\n",
    "\n",
    "mat = confusion_matrix(rounded_labels,y_pred)\n",
    "plot_confusion_matrix(mat,class_names=label.classes_, show_normed=True,figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the size of the graphs. The default size is (6,4).\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# graph the loss, the model above is configure to use \"mean squared error\" as the loss function\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(plt.rcParams[\"figure.figsize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the loss again skipping a bit of the start\n",
    "SKIP = 0\n",
    "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph of mean absolute error\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and validation mean absolute error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "#converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"kettle.tflite\", \"wb\").write(tflite_model)\n",
    "  \n",
    "import os\n",
    "basic_model_size = os.path.getsize(\"kettle.tflite\")\n",
    "print(\"Model is %d bytes\" % basic_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"const unsigned char model[] = {\" > model.h\n",
    "cat kettle.tflite | xxd -i             >> model.h\n",
    "echo \"};\"                              >> model.h\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
